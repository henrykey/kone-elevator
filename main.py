# Author: IBC-AI CO.
"""
KONE æµ‹è¯•æŠ¥å‘Šè‡ªåŠ¨åŒ–ç³»ç»Ÿ - ä¸»æ‰§è¡Œè„šæœ¬
è¿™æ˜¯ä¸€ä¸ªå®Œæ•´çš„è‡ªåŠ¨åŒ–ç³»ç»Ÿï¼Œç”¨äºæ‰§è¡ŒKONEç”µæ¢¯ç³»ç»ŸéªŒè¯æµ‹è¯•å¹¶ç”Ÿæˆç¬¦åˆæŒ‡å—æ ¼å¼çš„æŠ¥å‘Šã€‚

åŠŸèƒ½ç‰¹æ€§ï¼š
- æ‰§è¡Œ37é¡¹KONE SR-API v2.0éªŒè¯æµ‹è¯•
- ç”Ÿæˆå¤šæ ¼å¼æµ‹è¯•æŠ¥å‘Šï¼ˆMarkdownã€JSONã€HTMLã€Excelï¼‰
- è‡ªåŠ¨åŒ–ä¸‰é˜¶æ®µæ‰§è¡Œæµç¨‹
- å®Œæ•´çš„é”™è¯¯å¤„ç†å’Œæ—¥å¿—è®°å½•
- ä¸€é”®è¿è¡Œæ”¯æŒ

ä½¿ç”¨æ–¹æ³•ï¼š
    python main.py                          # ä½¿ç”¨é»˜è®¤é…ç½®
    python main.py --api-url http://localhost:8080  # æŒ‡å®šAPIåœ°å€
    python main.py --config custom_config.yml       # æŒ‡å®šé…ç½®æ–‡ä»¶
    python main.py --verbose                        # è¯¦ç»†æ—¥å¿—è¾“å‡º
"""

import asyncio
import argparse
import logging
import sys
import time
from datetime import datetime
from pathlib import Path
from typing import Dict, Any, List

# å¯¼å…¥é¡¹ç›®æ¨¡å—
from test_coordinator import KoneValidationTestCoordinator
from test_execution_phases import phase_1_setup, phase_2_core_tests, phase_3_report_generation
from building_data_manager import BuildingDataManager
from test_case_mapper import TestCaseMapper
from report_generator import ReportGenerator


def setup_logging(verbose: bool = False) -> None:
    """
    é…ç½®æ—¥å¿—ç³»ç»Ÿ
    
    Args:
        verbose: æ˜¯å¦å¯ç”¨è¯¦ç»†æ—¥å¿—
    """
    log_level = logging.DEBUG if verbose else logging.INFO
    
    # é…ç½®æ ¹æ—¥å¿—è®°å½•å™¨
    logging.basicConfig(
        level=log_level,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler('kone_validation.log', encoding='utf-8'),
            logging.StreamHandler(sys.stdout)
        ]
    )
    
    # è®¾ç½®httpxæ—¥å¿—çº§åˆ«
    logging.getLogger('httpx').setLevel(logging.WARNING)


def print_banner():
    """æ‰“å°ç³»ç»Ÿæ¨ªå¹…"""
    banner = """
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    KONE æµ‹è¯•æŠ¥å‘Šè‡ªåŠ¨åŒ–ç³»ç»Ÿ v2.0                                    â•‘
â•‘                                                                              â•‘
â•‘                            Author: IBC-AI CO.                               â•‘
â•‘                                                                              â•‘
â•‘  ğŸ¢ ç”µæ¢¯ç³»ç»ŸéªŒè¯æµ‹è¯• | ğŸ“Š å¤šæ ¼å¼æŠ¥å‘Šç”Ÿæˆ | ğŸ”„ ä¸‰é˜¶æ®µè‡ªåŠ¨åŒ–æµç¨‹                           â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""
    print(banner)


def print_system_info(args):
    """æ‰“å°ç³»ç»Ÿé…ç½®ä¿¡æ¯"""
    print("ğŸ”§ ç³»ç»Ÿé…ç½®ä¿¡æ¯:")
    print(f"   APIåœ°å€: {args.api_url}")
    print(f"   é…ç½®æ–‡ä»¶: {args.config}")
    print(f"   è¯¦ç»†æ—¥å¿—: {'å¯ç”¨' if args.verbose else 'ç¦ç”¨'}")
    print(f"   è¾“å‡ºç›®å½•: {args.output_dir}")
    print(f"   æ‰§è¡Œæ¨¡å¼: {args.mode}")
    
    # æ˜¾ç¤ºè¦æ‰§è¡Œçš„æµ‹è¯•ç”¨ä¾‹
    if hasattr(args, 'tests') and args.tests:
        try:
            test_cases = parse_test_cases(args.tests)
            test_summary = format_test_list(test_cases)
            print(f"   æµ‹è¯•èŒƒå›´: {test_summary} (å…±{len(test_cases)}é¡¹)")
        except ValueError as e:
            print(f"   æµ‹è¯•èŒƒå›´: âŒ æ ¼å¼é”™è¯¯ - {e}")
    else:
        print("   æµ‹è¯•èŒƒå›´: å…¨éƒ¨37é¡¹æµ‹è¯•")
    
    print()


async def run_coordinated_validation(api_url: str, config_path: str, test_cases: List[int] = None) -> Dict[str, Any]:
    """
    è¿è¡Œåè°ƒå¼éªŒè¯ï¼ˆä½¿ç”¨TestCoordinatorï¼‰
    
    Args:
        api_url: APIæœåŠ¡åœ°å€
        config_path: é…ç½®æ–‡ä»¶è·¯å¾„
        test_cases: æŒ‡å®šè¦æ‰§è¡Œçš„æµ‹è¯•ç”¨ä¾‹åˆ—è¡¨ï¼ŒNoneè¡¨ç¤ºæ‰§è¡Œå…¨éƒ¨
        
    Returns:
        dict: éªŒè¯ç»“æœ
    """
    logger = logging.getLogger(__name__)
    logger.info("ğŸš€ Starting coordinated validation using TestCoordinator...")
    
    if test_cases:
        logger.info(f"ğŸ“‹ Will execute {len(test_cases)} specific tests: {format_test_list(test_cases)}")
    
    async with KoneValidationTestCoordinator(api_url, config_path) as coordinator:
        if test_cases:
            # æ£€æŸ¥æ˜¯å¦æ”¯æŒéƒ¨åˆ†éªŒè¯ï¼Œå¦‚æœä¸æ”¯æŒåˆ™å›é€€åˆ°å…¨éƒ¨éªŒè¯
            if hasattr(coordinator, 'run_partial_validation'):
                result = await coordinator.run_partial_validation(test_cases)
            else:
                logger.warning("âš ï¸ TestCoordinatorä¸æ”¯æŒéƒ¨åˆ†éªŒè¯ï¼Œå°†æ‰§è¡Œå…¨éƒ¨æµ‹è¯•")
                result = await coordinator.run_full_validation()
        else:
            result = await coordinator.run_full_validation()
        return result


async def run_direct_validation(api_url: str, config_path: str, test_cases: List[int] = None) -> Dict[str, Any]:
    """
    è¿è¡Œç›´æ¥éªŒè¯ï¼ˆç›´æ¥ä½¿ç”¨ä¸‰é˜¶æ®µæ‰§è¡Œï¼‰
    
    Args:
        api_url: APIæœåŠ¡åœ°å€
        config_path: é…ç½®æ–‡ä»¶è·¯å¾„
        test_cases: æŒ‡å®šè¦æ‰§è¡Œçš„æµ‹è¯•ç”¨ä¾‹åˆ—è¡¨ï¼ŒNoneè¡¨ç¤ºæ‰§è¡Œå…¨éƒ¨
        
    Returns:
        dict: éªŒè¯ç»“æœ
    """
    logger = logging.getLogger(__name__)
    logger.info("ğŸš€ Starting direct validation using three-phase execution...")
    
    if test_cases:
        logger.info(f"ğŸ“‹ Will execute {len(test_cases)} specific tests: {format_test_list(test_cases)}")
    
    total_start_time = time.time()
    
    validation_result = {
        "execution_mode": "direct",
        "start_time": datetime.now().isoformat(),
        "phases": {},
        "summary": {},
        "reports": {},
        "test_scope": {
            "specified_tests": test_cases,
            "total_tests": len(test_cases) if test_cases else 37
        }
    }
    
    try:
        # é˜¶æ®µ1ï¼šç³»ç»Ÿé¢„æ£€æŸ¥
        logger.info("=" * 60)
        logger.info("ğŸ”§ PHASE 1: System Setup and Pre-checks")
        logger.info("=" * 60)
        
        phase1_result = await phase_1_setup(api_url, config_path)
        validation_result["phases"]["phase_1"] = phase1_result
        
        if phase1_result["status"] != "COMPLETED":
            raise Exception(f"Phase 1 failed: {phase1_result.get('error', 'Unknown error')}")
        
        logger.info(f"âœ… Phase 1 completed in {phase1_result['duration_ms']:.2f} ms")
        
        # é˜¶æ®µ2ï¼šæ ¸å¿ƒæµ‹è¯•æ‰§è¡Œ
        logger.info("=" * 60)
        logger.info("ğŸ§ª PHASE 2: Core Test Execution")
        logger.info("=" * 60)
        
        phase2_result = await phase_2_core_tests(phase1_result["data"], api_url, test_cases)
        validation_result["phases"]["phase_2"] = phase2_result
        
        if phase2_result["status"] == "COMPLETED":
            stats = phase2_result.get("statistics", {})
            logger.info(f"âœ… Phase 2 completed: {stats.get('total_tests', 0)} tests, "
                       f"{stats.get('success_rate', 0)}% success rate")
        else:
            logger.warning(f"âš ï¸ Phase 2 issues: {phase2_result.get('error', 'Unknown error')}")
        
        # é˜¶æ®µ3ï¼šæŠ¥å‘Šç”Ÿæˆ
        logger.info("=" * 60)
        logger.info("ğŸ“ PHASE 3: Report Generation")
        logger.info("=" * 60)
        
        metadata = {
            "company": "IBC-AI CO.",
            "test_date": validation_result["start_time"],
            "api_version": "2.0.0",
            "test_framework": "KONE SR-API v2.0",
            "api_base_url": api_url,
            "config_path": config_path
        }
        
        phase3_result = await phase_3_report_generation(
            phase2_result, 
            phase1_result["data"], 
            metadata
        )
        validation_result["phases"]["phase_3"] = phase3_result
        
        if phase3_result["status"] == "COMPLETED":
            validation_result["reports"] = phase3_result.get("reports", {})
            validation_result["saved_files"] = phase3_result.get("saved_files", {})
            logger.info(f"âœ… Phase 3 completed: {len(validation_result['reports'])} report formats generated")
        else:
            logger.error(f"âŒ Phase 3 failed: {phase3_result.get('error', 'Unknown error')}")
        
        # è®¡ç®—æ€»ä½“ç»“æœ
        completed_phases = sum(1 for phase in validation_result["phases"].values() 
                             if phase.get("status") == "COMPLETED")
        
        validation_result["summary"] = {
            "total_phases": 3,
            "completed_phases": completed_phases,
            "overall_status": "COMPLETED" if completed_phases == 3 else "PARTIALLY_COMPLETED",
            "total_duration_ms": (time.time() - total_start_time) * 1000,
            "has_reports": bool(validation_result.get("reports"))
        }
        
        if completed_phases == 3:
            logger.info("ğŸ‰ All phases completed successfully!")
        else:
            logger.info(f"âš ï¸ Partial completion: {completed_phases}/3 phases completed")
        
        return validation_result
        
    except Exception as e:
        logger.error(f"âŒ Direct validation failed: {e}")
        validation_result["summary"] = {
            "overall_status": "FAILED",
            "error": str(e),
            "total_duration_ms": (time.time() - total_start_time) * 1000
        }
        return validation_result


def print_execution_summary(result: Dict[str, Any]) -> None:
    """
    æ‰“å°æ‰§è¡Œæ‘˜è¦
    
    Args:
        result: æ‰§è¡Œç»“æœ
    """
    print("\n" + "=" * 80)
    print("ğŸ“Š EXECUTION SUMMARY")
    print("=" * 80)
    
    summary = result.get("summary", {})
    phases = result.get("phases", {})
    
    print(f"Overall Status: {summary.get('overall_status', 'Unknown')}")
    print(f"Completed Phases: {summary.get('completed_phases', 0)}/3")
    
    if "total_duration_ms" in summary:
        duration_seconds = summary["total_duration_ms"] / 1000
        print(f"Total Duration: {duration_seconds:.2f} seconds")
    
    print("\nPhase Status:")
    for phase_name, phase_data in phases.items():
        status = phase_data.get("status", "Unknown")
        status_icon = {"COMPLETED": "âœ…", "ERROR": "âŒ", "FAILED": "âŒ", "SKIPPED": "â­ï¸"}.get(status, "â“")
        print(f"  {phase_name}: {status_icon} {status}")
        
        if phase_data.get("statistics"):
            stats = phase_data["statistics"]
            print(f"    â†’ Tests: {stats.get('total_tests', 0)}, "
                  f"Success Rate: {stats.get('success_rate', 0)}%")
    
    # æŠ¥å‘Šæ–‡ä»¶ä¿¡æ¯
    if result.get("reports"):
        print(f"\nGenerated Reports: {list(result['reports'].keys())}")
    
    if result.get("saved_files"):
        print("\nSaved Files:")
        for format_name, filepath in result["saved_files"].items():
            print(f"  ğŸ“„ {format_name}: {filepath}")
    
    print("=" * 80)


def parse_test_cases(test_string: str) -> List[int]:
    """
    è§£ææµ‹è¯•ç”¨ä¾‹å­—ç¬¦ä¸²ï¼Œæ”¯æŒå¤šç§æ ¼å¼
    
    Args:
        test_string: æµ‹è¯•ç”¨ä¾‹å­—ç¬¦ä¸²ï¼Œå¦‚ "1,2,5" æˆ– "1-10" æˆ– "1,3-5,8"
        
    Returns:
        list: æµ‹è¯•ç”¨ä¾‹ç¼–å·åˆ—è¡¨
        
    Examples:
        parse_test_cases("1") -> [1]
        parse_test_cases("1,2,5") -> [1, 2, 5]
        parse_test_cases("1-5") -> [1, 2, 3, 4, 5]
        parse_test_cases("1,3-5,8") -> [1, 3, 4, 5, 8]
    """
    if not test_string:
        return list(range(1, 38))  # é»˜è®¤å…¨éƒ¨37é¡¹æµ‹è¯•
    
    test_cases = set()
    
    # æŒ‰é€—å·åˆ†å‰²å„ä¸ªéƒ¨åˆ†
    parts = test_string.split(',')
    
    for part in parts:
        part = part.strip()
        if '-' in part:
            # å¤„ç†èŒƒå›´ï¼Œå¦‚ "1-5"
            try:
                start, end = part.split('-', 1)
                start_num = int(start.strip())
                end_num = int(end.strip())
                
                if start_num > end_num:
                    raise ValueError(f"Invalid range: {part} (start > end)")
                if start_num < 1 or end_num > 37:
                    raise ValueError(f"Test number out of range: {part} (valid: 1-37)")
                
                test_cases.update(range(start_num, end_num + 1))
            except ValueError as e:
                if "invalid literal" in str(e):
                    raise ValueError(f"Invalid range format: {part}")
                raise
        else:
            # å¤„ç†å•ä¸ªæ•°å­—
            try:
                test_num = int(part)
                if test_num < 1 or test_num > 37:
                    raise ValueError(f"Test number out of range: {test_num} (valid: 1-37)")
                test_cases.add(test_num)
            except ValueError:
                raise ValueError(f"Invalid test number: {part}")
    
    return sorted(list(test_cases))


def format_test_list(test_cases: List[int]) -> str:
    """
    æ ¼å¼åŒ–æµ‹è¯•ç”¨ä¾‹åˆ—è¡¨ä¸ºæ˜“è¯»çš„å­—ç¬¦ä¸²
    
    Args:
        test_cases: æµ‹è¯•ç”¨ä¾‹ç¼–å·åˆ—è¡¨
        
    Returns:
        str: æ ¼å¼åŒ–çš„å­—ç¬¦ä¸²
    """
    if not test_cases:
        return "æ— "
    
    if len(test_cases) == 37:
        return "å…¨éƒ¨37é¡¹æµ‹è¯•"
    
    # å°†è¿ç»­çš„æ•°å­—ç»„åˆæˆèŒƒå›´
    ranges = []
    start = test_cases[0]
    end = start
    
    for i in range(1, len(test_cases)):
        if test_cases[i] == end + 1:
            end = test_cases[i]
        else:
            if start == end:
                ranges.append(str(start))
            else:
                ranges.append(f"{start}-{end}")
            start = end = test_cases[i]
    
    # æ·»åŠ æœ€åä¸€ä¸ªèŒƒå›´
    if start == end:
        ranges.append(str(start))
    else:
        ranges.append(f"{start}-{end}")
    
    return ", ".join(ranges)


def parse_arguments():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(
        description="KONEæµ‹è¯•æŠ¥å‘Šè‡ªåŠ¨åŒ–ç³»ç»Ÿ",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹ç”¨æ³•:
  python main.py                                    # ä½¿ç”¨é»˜è®¤é…ç½®ï¼Œæ‰§è¡Œå…¨éƒ¨æµ‹è¯•
  python main.py --api-url http://localhost:8080    # æŒ‡å®šAPIåœ°å€
  python main.py --config custom_config.yml         # æŒ‡å®šé…ç½®æ–‡ä»¶
  python main.py --mode direct --verbose            # ä½¿ç”¨ç›´æ¥æ¨¡å¼ï¼Œè¯¦ç»†æ—¥å¿—
  
æµ‹è¯•ç”¨ä¾‹é€‰æ‹©:
  python main.py --tests 1                          # åªæ‰§è¡Œæµ‹è¯•1
  python main.py --tests 1,2,5                      # æ‰§è¡Œæµ‹è¯•1ã€2ã€5
  python main.py --tests 1-10                       # æ‰§è¡Œæµ‹è¯•1åˆ°10
  python main.py --tests 1,3-5,8,10-12             # æ··åˆæ ¼å¼ï¼š1ã€3åˆ°5ã€8ã€10åˆ°12
  python main.py --dry-run --tests 1-5              # æ¨¡æ‹Ÿè¿è¡Œæµ‹è¯•1åˆ°5
        """
    )
    
    parser.add_argument(
        "--api-url", 
        default="http://localhost:8000",
        help="FastAPIæœåŠ¡åœ°å€ (é»˜è®¤: http://localhost:8000)"
    )
    
    parser.add_argument(
        "--config",
        default="virtual_building_config.yml", 
        help="è™šæ‹Ÿå»ºç­‘é…ç½®æ–‡ä»¶è·¯å¾„ (é»˜è®¤: virtual_building_config.yml)"
    )
    
    parser.add_argument(
        "--mode",
        choices=["coordinated", "direct"],
        default="coordinated",
        help="æ‰§è¡Œæ¨¡å¼: coordinated(ä½¿ç”¨TestCoordinator) æˆ– direct(ç›´æ¥ä¸‰é˜¶æ®µ) (é»˜è®¤: coordinated)"
    )
    
    parser.add_argument(
        "--output-dir",
        default="./reports",
        help="æŠ¥å‘Šè¾“å‡ºç›®å½• (é»˜è®¤: ./reports)"
    )
    
    parser.add_argument(
        "--verbose", "-v",
        action="store_true",
        help="å¯ç”¨è¯¦ç»†æ—¥å¿—è¾“å‡º"
    )
    
    parser.add_argument(
        "--dry-run",
        action="store_true", 
        help="æ¨¡æ‹Ÿè¿è¡Œï¼Œä¸æ‰§è¡Œå®é™…æµ‹è¯•"
    )
    
    parser.add_argument(
        "--tests", "-t",
        type=str,
        help="æŒ‡å®šè¦æ‰§è¡Œçš„æµ‹è¯•ç”¨ä¾‹ï¼Œæ”¯æŒå¤šç§æ ¼å¼:\n"
             "  å•ä¸ªæµ‹è¯•: --tests 1\n"
             "  å¤šä¸ªæµ‹è¯•: --tests 1,2,5\n"
             "  èŒƒå›´æµ‹è¯•: --tests 1-10\n"
             "  æ··åˆæ ¼å¼: --tests 1,3-5,8,10-12\n"
             "  å¦‚ä¸æŒ‡å®šï¼Œåˆ™æ‰§è¡Œå…¨éƒ¨37é¡¹æµ‹è¯•"
    )
    
    return parser.parse_args()


async def main():
    """
    ä¸»æ‰§è¡Œå‡½æ•°
    æ‰§è¡Œä¸‰é˜¶æ®µæµ‹è¯•æµç¨‹ï¼š
    1. ç³»ç»Ÿé¢„æ£€æŸ¥
    2. æ‰§è¡Œæµ‹è¯•å¥—ä»¶  
    3. ç”ŸæˆæŠ¥å‘Š
    """
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    args = parse_arguments()
    
    # è®¾ç½®æ—¥å¿—
    setup_logging(args.verbose)
    logger = logging.getLogger(__name__)
    
    # æ‰“å°æ¨ªå¹…å’Œé…ç½®ä¿¡æ¯
    print_banner()
    print_system_info(args)
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = Path(args.output_dir)
    output_dir.mkdir(exist_ok=True)
    
    # è§£ææµ‹è¯•ç”¨ä¾‹
    test_cases = None
    if hasattr(args, 'tests') and args.tests:
        try:
            test_cases = parse_test_cases(args.tests)
            logger.info(f"ğŸ“‹ å°†æ‰§è¡ŒæŒ‡å®šçš„{len(test_cases)}é¡¹æµ‹è¯•: {format_test_list(test_cases)}")
        except ValueError as e:
            logger.error(f"âŒ æµ‹è¯•ç”¨ä¾‹æ ¼å¼é”™è¯¯: {e}")
            print(f"\nâŒ é”™è¯¯: {e}")
            print("\nâœ… æ­£ç¡®æ ¼å¼ç¤ºä¾‹:")
            print("   --tests 1          # å•ä¸ªæµ‹è¯•")
            print("   --tests 1,2,5      # å¤šä¸ªæµ‹è¯•") 
            print("   --tests 1-10       # èŒƒå›´æµ‹è¯•")
            print("   --tests 1,3-5,8    # æ··åˆæ ¼å¼")
            sys.exit(1)
    
    # éªŒè¯é…ç½®æ–‡ä»¶å­˜åœ¨
    if not Path(args.config).exists():
        logger.error(f"âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {args.config}")
        sys.exit(1)
    
    # æ¨¡æ‹Ÿè¿è¡Œæ¨¡å¼
    if args.dry_run:
        logger.info("ğŸ” DRY RUN MODE - ä¸ä¼šæ‰§è¡Œå®é™…æµ‹è¯•")
        print("âœ… é…ç½®éªŒè¯é€šè¿‡ï¼Œæ‰€æœ‰å¿…éœ€æ–‡ä»¶éƒ½å­˜åœ¨")
        print("ğŸ“‹ å°†æ‰§è¡Œä»¥ä¸‹æ“ä½œ:")
        print("   1. ç³»ç»Ÿé¢„æ£€æŸ¥å’Œç»„ä»¶åˆå§‹åŒ–")
        
        if test_cases:
            print(f"   2. æ‰§è¡ŒæŒ‡å®šçš„{len(test_cases)}é¡¹KONEéªŒè¯æµ‹è¯•: {format_test_list(test_cases)}")
        else:
            print("   2. æ‰§è¡Œå…¨éƒ¨37é¡¹KONEéªŒè¯æµ‹è¯•")
            
        print("   3. ç”Ÿæˆå¤šæ ¼å¼æµ‹è¯•æŠ¥å‘Š")
        print(f"   4. ä¿å­˜æŠ¥å‘Šåˆ°: {output_dir}")
        return
    
    start_time = time.time()
    
    try:
        # æ ¹æ®æ¨¡å¼é€‰æ‹©æ‰§è¡Œæ–¹å¼
        if args.mode == "coordinated":
            result = await run_coordinated_validation(args.api_url, args.config, test_cases)
        else:
            result = await run_direct_validation(args.api_url, args.config, test_cases)
        
        # æ‰“å°æ‰§è¡Œæ‘˜è¦
        print_execution_summary(result)
        
        # åˆ¤æ–­æ‰§è¡Œç»“æœ
        overall_status = result.get("summary", {}).get("overall_status", "UNKNOWN")
        
        if overall_status == "COMPLETED":
            logger.info("ğŸ‰ KONEéªŒè¯æµ‹è¯•ç³»ç»Ÿæ‰§è¡Œå®Œæˆï¼")
            
            # è¾“å‡ºæŠ¥å‘Šæ–‡ä»¶ä½ç½®
            if result.get("saved_files"):
                print("\nğŸ“ æŠ¥å‘Šæ–‡ä»¶å·²ç”Ÿæˆ:")
                for format_name, filepath in result["saved_files"].items():
                    print(f"   {format_name}: {filepath}")
            
            sys.exit(0)
            
        elif overall_status == "PARTIALLY_COMPLETED":
            logger.warning("âš ï¸ KONEéªŒè¯æµ‹è¯•éƒ¨åˆ†å®Œæˆ")
            sys.exit(0)
            
        else:
            logger.error("âŒ KONEéªŒè¯æµ‹è¯•æ‰§è¡Œå¤±è´¥")
            error_msg = result.get("summary", {}).get("error", "Unknown error")
            print(f"é”™è¯¯ä¿¡æ¯: {error_msg}")
            sys.exit(1)
            
    except KeyboardInterrupt:
        logger.info("â¹ï¸ ç”¨æˆ·ä¸­æ–­æ‰§è¡Œ")
        sys.exit(130)
        
    except Exception as e:
        logger.error(f"âŒ ç³»ç»Ÿæ‰§è¡Œé”™è¯¯: {e}", exc_info=True)
        sys.exit(1)
        
    finally:
        total_time = time.time() - start_time
        logger.info(f"â±ï¸ æ€»æ‰§è¡Œæ—¶é—´: {total_time:.2f} ç§’")


if __name__ == "__main__":
    """
    ç¨‹åºå…¥å£ç‚¹
    æ”¯æŒä¸€é”®è¿è¡ŒKONEæµ‹è¯•æŠ¥å‘Šè‡ªåŠ¨åŒ–ç³»ç»Ÿ
    """
    try:
        asyncio.run(main())
    except Exception as e:
        print(f"âŒ ç¨‹åºå¯åŠ¨å¤±è´¥: {e}")
        sys.exit(1)
