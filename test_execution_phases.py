# Author: IBC-AI CO.
"""
KONE æµ‹è¯•æ‰§è¡Œæµç¨‹
å®žçŽ°ä¸‰é˜¶æ®µæµ‹è¯•æ‰§è¡Œï¼šç³»ç»Ÿé¢„æ£€æŸ¥ã€æ ¸å¿ƒæµ‹è¯•ã€æŠ¥å‘Šç”Ÿæˆ
"""

import asyncio
import httpx
import logging
import time
from datetime import datetime
from typing import Dict, List, Any, Optional, Tuple
from test_case_mapper import TestCaseMapper, TestCaseConfig
from building_data_manager import BuildingDataManager
from report_generator import ReportGenerator, TestResult

logger = logging.getLogger(__name__)


async def phase_1_setup(api_base_url: str = "http://localhost:8000", 
                       config_path: str = "virtual_building_config.yml") -> Dict[str, Any]:
    """
    é˜¶æ®µ1ï¼šç³»ç»Ÿé¢„æ£€æŸ¥
    æ£€æŸ¥APIã€åŠ è½½é…ç½®ã€è¿žæŽ¥éªŒè¯
    
    Args:
        api_base_url: APIæœåŠ¡åœ°å€
        config_path: é…ç½®æ–‡ä»¶è·¯å¾„
        
    Returns:
        dict: é¢„æ£€æŸ¥ç»“æžœ
    """
    logger.info("ðŸš€ Phase 1: System Setup and Pre-checks")
    start_time = time.time()
    
    setup_result = {
        "phase": "phase_1_setup",
        "status": "IN_PROGRESS",
        "start_time": datetime.now().isoformat(),
        "checks": {},
        "data": {}
    }
    
    try:
        # 1. APIè¿žé€šæ€§æ£€æŸ¥
        logger.info("1ï¸âƒ£ Checking API connectivity...")
        async with httpx.AsyncClient(timeout=30.0) as client:
            try:
                response = await client.get(f"{api_base_url.rstrip('/')}/")
                if response.status_code == 200:
                    api_info = response.json()
                    setup_result["checks"]["api_connectivity"] = {
                        "status": "PASS",
                        "response_time_ms": response.elapsed.total_seconds() * 1000,
                        "api_info": api_info
                    }
                    logger.info(f"âœ… API connectivity check passed: {api_info.get('name')}")
                else:
                    setup_result["checks"]["api_connectivity"] = {
                        "status": "FAIL",
                        "error": f"HTTP {response.status_code}",
                        "response_time_ms": response.elapsed.total_seconds() * 1000
                    }
                    logger.error(f"âŒ API connectivity failed: {response.status_code}")
            except Exception as e:
                setup_result["checks"]["api_connectivity"] = {
                    "status": "ERROR",
                    "error": str(e)
                }
                logger.error(f"âŒ API connectivity error: {e}")
        
        # 2. å»ºç­‘æ•°æ®ç®¡ç†å™¨åˆå§‹åŒ–
        logger.info("2ï¸âƒ£ Initializing Building Data Manager...")
        try:
            building_manager = BuildingDataManager(config_path)
            building_summary = building_manager.get_building_summary()
            
            setup_result["checks"]["building_config"] = {
                "status": "PASS",
                "building_summary": building_summary
            }
            setup_result["data"]["building_manager"] = building_manager
            logger.info(f"âœ… Building config loaded: {building_summary['building_id']}")
        except Exception as e:
            setup_result["checks"]["building_config"] = {
                "status": "ERROR",
                "error": str(e)
            }
            logger.error(f"âŒ Building config error: {e}")
        
        # 3. æµ‹è¯•ç”¨ä¾‹æ˜ å°„å™¨åˆå§‹åŒ–
        logger.info("3ï¸âƒ£ Initializing Test Case Mapper...")
        try:
            building_id = setup_result["data"].get("building_manager", BuildingDataManager()).get_building_id()
            test_mapper = TestCaseMapper(building_id)
            mapper_summary = test_mapper.get_test_summary()
            
            setup_result["checks"]["test_mapper"] = {
                "status": "PASS",
                "test_summary": mapper_summary
            }
            setup_result["data"]["test_mapper"] = test_mapper
            logger.info(f"âœ… Test mapper initialized: {mapper_summary['total_tests']} tests")
        except Exception as e:
            setup_result["checks"]["test_mapper"] = {
                "status": "ERROR",
                "error": str(e)
            }
            logger.error(f"âŒ Test mapper error: {e}")
        
        # 4. æŠ¥å‘Šç”Ÿæˆå™¨åˆå§‹åŒ–
        logger.info("4ï¸âƒ£ Initializing Report Generator...")
        try:
            report_generator = ReportGenerator("IBC-AI CO.")
            setup_result["checks"]["report_generator"] = {
                "status": "PASS",
                "company": "IBC-AI CO."
            }
            setup_result["data"]["report_generator"] = report_generator
            logger.info("âœ… Report generator initialized")
        except Exception as e:
            setup_result["checks"]["report_generator"] = {
                "status": "ERROR",
                "error": str(e)
            }
            logger.error(f"âŒ Report generator error: {e}")
        
        # 5. APIæœåŠ¡çŠ¶æ€æ£€æŸ¥
        logger.info("5ï¸âƒ£ Checking API service status...")
        async with httpx.AsyncClient(timeout=30.0) as client:
            try:
                response = await client.get(f"{api_base_url.rstrip('/')}/api/elevator/status")
                if response.status_code == 200:
                    status_info = response.json()
                    setup_result["checks"]["service_status"] = {
                        "status": "PASS",
                        "service_info": status_info
                    }
                    logger.info("âœ… Service status check passed")
                else:
                    setup_result["checks"]["service_status"] = {
                        "status": "FAIL",
                        "error": f"HTTP {response.status_code}"
                    }
                    logger.warning(f"âš ï¸ Service status check failed: {response.status_code}")
            except Exception as e:
                setup_result["checks"]["service_status"] = {
                    "status": "ERROR",
                    "error": str(e)
                }
                logger.warning(f"âš ï¸ Service status error: {e}")
        
        # è®¡ç®—æ€»ä½“çŠ¶æ€
        all_checks = setup_result["checks"]
        critical_checks = ["api_connectivity", "building_config", "test_mapper", "report_generator"]
        
        failed_critical = [check for check in critical_checks 
                          if all_checks.get(check, {}).get("status") not in ["PASS"]]
        
        if not failed_critical:
            setup_result["status"] = "COMPLETED"
            logger.info("âœ… Phase 1 completed successfully")
        else:
            setup_result["status"] = "FAILED"
            setup_result["failed_checks"] = failed_critical
            logger.error(f"âŒ Phase 1 failed: {failed_critical}")
        
        # æ·»åŠ æ‰§è¡Œæ—¶é—´
        setup_result["duration_ms"] = (time.time() - start_time) * 1000
        setup_result["end_time"] = datetime.now().isoformat()
        
        return setup_result
        
    except Exception as e:
        setup_result["status"] = "ERROR"
        setup_result["error"] = str(e)
        setup_result["duration_ms"] = (time.time() - start_time) * 1000
        setup_result["end_time"] = datetime.now().isoformat()
        logger.error(f"âŒ Phase 1 setup error: {e}")
        return setup_result


async def phase_2_core_tests(setup_data: Dict[str, Any], 
                           api_base_url: str = "http://localhost:8000") -> Dict[str, Any]:
    """
    é˜¶æ®µ2ï¼šæ ¸å¿ƒæµ‹è¯•æ‰§è¡Œ
    æ‰§è¡Œ37é¡¹æµ‹è¯•ï¼Œç»„ç»‡ç»“æžœ
    
    Args:
        setup_data: é˜¶æ®µ1çš„è®¾ç½®æ•°æ®
        api_base_url: APIæœåŠ¡åœ°å€
        
    Returns:
        dict: æµ‹è¯•æ‰§è¡Œç»“æžœ
    """
    logger.info("ðŸ§ª Phase 2: Core Test Execution")
    start_time = time.time()
    
    test_result = {
        "phase": "phase_2_core_tests",
        "status": "IN_PROGRESS",
        "start_time": datetime.now().isoformat(),
        "test_results": [],
        "statistics": {},
        "errors": []
    }
    
    try:
        # ä»Žè®¾ç½®æ•°æ®ä¸­èŽ·å–å¿…è¦ç»„ä»¶
        test_mapper = setup_data.get("test_mapper")
        building_manager = setup_data.get("building_manager")
        test_filter = setup_data.get("test_filter")  # æ–°å¢žï¼šæµ‹è¯•è¿‡æ»¤å™¨
        
        if not test_mapper or not building_manager:
            raise Exception("Missing required components from phase 1 setup")
        
        # èŽ·å–æµ‹è¯•ç”¨ä¾‹ï¼ˆæ”¯æŒè¿‡æ»¤ï¼‰
        if test_filter:
            # å¦‚æžœæœ‰è¿‡æ»¤å™¨ï¼Œåªæ‰§è¡ŒæŒ‡å®šçš„æµ‹è¯•
            # å°†æ•´æ•°æµ‹è¯•ç”¨ä¾‹è½¬æ¢ä¸ºå­—ç¬¦ä¸²æ ¼å¼
            string_test_filter = []
            for test_case in test_filter:
                if isinstance(test_case, int):
                    string_test_filter.append(f"Test_{test_case}")
                else:
                    string_test_filter.append(str(test_case))
            
            all_test_ids = [tid for tid in test_mapper.get_all_test_ids() if tid in string_test_filter]
            logger.info(f"ðŸ“‹ Executing {len(all_test_ids)}/{len(test_filter)} filtered tests...")
        else:
            # å¦åˆ™æ‰§è¡Œæ‰€æœ‰æµ‹è¯•
            all_test_ids = test_mapper.get_all_test_ids()
            logger.info(f"ðŸ“‹ Executing all {len(all_test_ids)} tests...")
        
        # åˆå§‹åŒ–HTTPå®¢æˆ·ç«¯
        async with httpx.AsyncClient(timeout=30.0) as client:
            
            # æ‰¹é‡æ‰§è¡Œæµ‹è¯•
            for i, test_id in enumerate(all_test_ids, 1):
                logger.info(f"ðŸ” Executing test {i}/{len(all_test_ids)}: {test_id}")
                
                test_config = test_mapper.get_test_case(test_id)
                if not test_config:
                    logger.warning(f"âš ï¸ Test config not found for {test_id}")
                    continue
                
                # æ‰§è¡Œå•ä¸ªæµ‹è¯•
                result = await _execute_single_test(client, test_config, building_manager, api_base_url, test_id)
                test_result["test_results"].append(result)
                
                # è®°å½•è¿›åº¦
                if i % 5 == 0:
                    logger.info(f"ðŸ“Š Progress: {i}/{len(all_test_ids)} tests completed")
        
        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        test_result["statistics"] = _calculate_test_statistics(test_result["test_results"])
        test_result["status"] = "COMPLETED"
        
        execution_mode = "filtered" if test_filter else "full"
        logger.info(f"âœ… Phase 2 completed ({execution_mode}): {test_result['statistics']['total_tests']} tests executed")
        
    except Exception as e:
        test_result["status"] = "ERROR"
        test_result["error"] = str(e)
        test_result["errors"].append(str(e))
        logger.error(f"âŒ Phase 2 execution error: {e}")
    
    # æ·»åŠ æ‰§è¡Œæ—¶é—´
    test_result["duration_ms"] = (time.time() - start_time) * 1000
    test_result["end_time"] = datetime.now().isoformat()
    
    return test_result


async def phase_2_partial_tests(setup_data: Dict[str, Any], 
                               api_base_url: str = "http://localhost:8000",
                               test_cases: List[int] = None) -> Dict[str, Any]:
    """
    é˜¶æ®µ2ï¼šéƒ¨åˆ†æµ‹è¯•æ‰§è¡Œ
    åªæ‰§è¡ŒæŒ‡å®šçš„æµ‹è¯•ç”¨ä¾‹
    
    Args:
        setup_data: é˜¶æ®µ1çš„è®¾ç½®æ•°æ®
        api_base_url: APIæœåŠ¡åœ°å€
        test_cases: è¦æ‰§è¡Œçš„æµ‹è¯•ç”¨ä¾‹ç¼–å·åˆ—è¡¨
        
    Returns:
        dict: æµ‹è¯•æ‰§è¡Œç»“æžœ
    """
    logger.info(f"ðŸ§ª Phase 2: Partial Test Execution for {len(test_cases) if test_cases else 0} test cases")
    start_time = time.time()
    
    test_result = {
        "phase": "phase_2_partial_tests",
        "status": "IN_PROGRESS",
        "start_time": datetime.now().isoformat(),
        "test_results": [],
        "statistics": {},
        "errors": [],
        "execution_mode": "partial",
        "selected_tests": test_cases or []
    }
    
    try:
        # ä»Žè®¾ç½®æ•°æ®ä¸­èŽ·å–å¿…è¦ç»„ä»¶
        test_mapper = setup_data.get("test_mapper")
        building_manager = setup_data.get("building_manager")
        
        if not test_mapper or not building_manager:
            raise Exception("Missing required components from phase 1 setup")
        
        if not test_cases:
            raise Exception("No test cases specified for partial execution")
        
        # èŽ·å–æ‰€æœ‰å¯ç”¨çš„æµ‹è¯•ID
        all_available_ids = test_mapper.get_all_test_ids()
        
        # å°†æ•´æ•°æµ‹è¯•ç”¨ä¾‹è½¬æ¢ä¸ºå­—ç¬¦ä¸²æ ¼å¼
        string_test_cases = []
        for test_case in test_cases:
            if isinstance(test_case, int):
                string_test_cases.append(f"Test_{test_case}")
            else:
                string_test_cases.append(str(test_case))
        
        # è¿‡æ»¤å‡ºå­˜åœ¨çš„æµ‹è¯•ç”¨ä¾‹
        valid_test_ids = [tid for tid in string_test_cases if tid in all_available_ids]
        invalid_test_ids = [tid for tid in string_test_cases if tid not in all_available_ids]
        
        if invalid_test_ids:
            logger.warning(f"âš ï¸ Invalid test IDs will be skipped: {invalid_test_ids}")
        
        if not valid_test_ids:
            raise Exception("No valid test cases found in the specified list")
        
        logger.info(f"ðŸ“‹ Executing {len(valid_test_ids)} valid tests out of {len(test_cases)} requested...")
        
        # åˆå§‹åŒ–HTTPå®¢æˆ·ç«¯
        async with httpx.AsyncClient(timeout=30.0) as client:
            
            # æ‰¹é‡æ‰§è¡ŒæŒ‡å®šçš„æµ‹è¯•
            for i, test_id in enumerate(valid_test_ids, 1):
                logger.info(f"ðŸ” Executing test {i}/{len(valid_test_ids)}: {test_id}")
                
                test_config = test_mapper.get_test_case(test_id)
                if not test_config:
                    logger.warning(f"âš ï¸ Test config not found for {test_id}")
                    continue
                
                # æ‰§è¡Œå•ä¸ªæµ‹è¯•
                result = await _execute_single_test(client, test_config, building_manager, api_base_url, test_id)
                test_result["test_results"].append(result)
                
                # è®°å½•è¿›åº¦
                if i % 3 == 0 or i == len(valid_test_ids):
                    logger.info(f"ðŸ“Š Progress: {i}/{len(valid_test_ids)} tests completed")
        
        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        test_result["statistics"] = _calculate_test_statistics(test_result["test_results"])
        test_result["statistics"]["requested_tests"] = len(test_cases)
        test_result["statistics"]["valid_tests"] = len(valid_test_ids)
        test_result["statistics"]["invalid_tests"] = len(invalid_test_ids)
        test_result["status"] = "COMPLETED"
        
        logger.info(f"âœ… Phase 2 partial execution completed: {test_result['statistics']['total_tests']} tests executed")
        
    except Exception as e:
        test_result["status"] = "ERROR"
        test_result["error"] = str(e)
        test_result["errors"].append(str(e))
        logger.error(f"âŒ Phase 2 partial execution error: {e}")
    
    # æ·»åŠ æ‰§è¡Œæ—¶é—´
    test_result["duration_ms"] = (time.time() - start_time) * 1000
    test_result["end_time"] = datetime.now().isoformat()
    
    return test_result


async def phase_3_report_generation(test_results: Dict[str, Any], 
                                  setup_data: Dict[str, Any],
                                  metadata: Dict[str, Any]) -> Dict[str, Any]:
    """
    é˜¶æ®µ3ï¼šæŠ¥å‘Šç”Ÿæˆ
    æ ¹æ®metadataå’Œæµ‹è¯•ç»“æžœç”ŸæˆæŠ¥å‘Šå¹¶è¿”å›ž
    
    Args:
        test_results: é˜¶æ®µ2çš„æµ‹è¯•ç»“æžœ
        setup_data: é˜¶æ®µ1çš„è®¾ç½®æ•°æ®
        metadata: æµ‹è¯•å…ƒæ•°æ®
        
    Returns:
        dict: æŠ¥å‘Šç”Ÿæˆç»“æžœ
    """
    logger.info("ðŸ“ Phase 3: Report Generation")
    start_time = time.time()
    
    report_result = {
        "phase": "phase_3_report_generation",
        "status": "IN_PROGRESS",
        "start_time": datetime.now().isoformat(),
        "reports": {},
        "saved_files": {}
    }
    
    try:
        # ä»Žè®¾ç½®æ•°æ®ä¸­èŽ·å–æŠ¥å‘Šç”Ÿæˆå™¨
        report_generator = setup_data.get("report_generator")
        if not report_generator:
            raise Exception("Report generator not available from phase 1 setup")
        
        # è½¬æ¢æµ‹è¯•ç»“æžœä¸ºReportGeneratoræœŸæœ›çš„æ ¼å¼
        formatted_results = []
        for result_data in test_results.get("test_results", []):
            test_result = TestResult(
                test_id=result_data["test_id"],
                name=result_data["name"],
                status=result_data["status"],
                duration_ms=result_data["duration_ms"],
                error_message=result_data.get("error_message"),
                response_data=result_data.get("response_data"),
                category=result_data.get("category")
            )
            formatted_results.append(test_result)
        
        # å‡†å¤‡å®Œæ•´çš„å…ƒæ•°æ®
        complete_metadata = {
            **metadata,
            "building_id": setup_data.get("building_manager", {}).get_building_id() if setup_data.get("building_manager") else "Unknown",
            "total_test_duration_ms": test_results.get("duration_ms", 0),
            "test_execution_time": test_results.get("end_time"),
            "setup_duration_ms": setup_data.get("duration_ms", 0) if isinstance(setup_data, dict) else 0
        }
        
        # ç”Ÿæˆå¤šæ ¼å¼æŠ¥å‘Š
        logger.info("ðŸ“Š Generating multi-format reports...")
        reports = report_generator.generate_report(formatted_results, complete_metadata, "reports")
        
        if "error" in reports:
            raise Exception(f"Report generation failed: {reports['error']}")
        
        report_result["reports"] = reports
        
        # ä¿å­˜æŠ¥å‘Šæ–‡ä»¶
        logger.info("ðŸ’¾ Saving report files...")
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        saved_files = report_generator.save_reports_to_files(reports, f"KONE_Validation_Report_{timestamp}")
        
        if "error" in saved_files:
            logger.warning(f"âš ï¸ File saving warning: {saved_files['error']}")
        else:
            report_result["saved_files"] = saved_files
            logger.info(f"âœ… Reports saved: {list(saved_files.keys())}")
        
        report_result["status"] = "COMPLETED"
        
        # è¾“å‡ºæŠ¥å‘Šæ‘˜è¦
        stats = test_results.get("statistics", {})
        logger.info(f"ðŸ“ˆ Report Summary:")
        logger.info(f"   Total Tests: {stats.get('total_tests', 0)}")
        logger.info(f"   Success Rate: {stats.get('success_rate', 0)}%")
        logger.info(f"   Generated Formats: {len(reports)}")
        
    except Exception as e:
        report_result["status"] = "ERROR"
        report_result["error"] = str(e)
        logger.error(f"âŒ Phase 3 report generation error: {e}")
    
    # æ·»åŠ æ‰§è¡Œæ—¶é—´
    report_result["duration_ms"] = (time.time() - start_time) * 1000
    report_result["end_time"] = datetime.now().isoformat()
    
    return report_result


async def _execute_single_test(client: httpx.AsyncClient, 
                             test_config: TestCaseConfig,
                             building_manager: BuildingDataManager,
                             api_base_url: str,
                             test_id: str = None) -> Dict[str, Any]:
    """
    æ‰§è¡Œå•ä¸ªæµ‹è¯•ç”¨ä¾‹
    
    Args:
        client: HTTPå®¢æˆ·ç«¯
        test_config: æµ‹è¯•é…ç½®
        building_manager: å»ºç­‘æ•°æ®ç®¡ç†å™¨
        api_base_url: APIåŸºç¡€URL
        test_id: æµ‹è¯•IDï¼ˆå¦‚ Test_1, Test_2ç­‰ï¼‰
        
    Returns:
        dict: æµ‹è¯•ç»“æžœ
    """
    start_time = time.time()
    
    result = {
        "test_id": test_id or test_config.name,  # ä¼˜å…ˆä½¿ç”¨ä¼ å…¥çš„test_id
        "name": test_config.name,
        "category": test_config.category.value,
        "status": "UNKNOWN",
        "duration_ms": 0,
        "error_message": None,
        "response_data": None,
        "request_data": None
    }
    
    try:
        # å‡†å¤‡è¯·æ±‚å‚æ•°
        params = test_config.parameters.copy()
        
        # ä¸ºéœ€è¦éšæœºæ•°æ®çš„æµ‹è¯•ç”Ÿæˆå‚æ•°
        if test_config.name in ["Test_6", "Test_7", "Test_8", "Test_10", "Test_22"]:  # å‘¼å«æµ‹è¯•
            if "source" in params and "destination" in params:
                source, dest = building_manager.get_random_floor_pair()
                params["source"] = source
                params["destination"] = dest
        
        # æž„å»ºè¯·æ±‚URL
        url = f"{api_base_url.rstrip('/')}{test_config.endpoint}"
        
        # è®°å½•è¯·æ±‚æ•°æ®
        result["request_data"] = {
            "method": test_config.http_method.value,
            "url": url,
            "parameters": params
        }
        
        # æ‰§è¡ŒHTTPè¯·æ±‚
        if test_config.http_method.value == "GET":
            response = await client.get(url, params=params)
        elif test_config.http_method.value == "POST":
            # ç‰¹æ®Šå¤„ç†å–æ¶ˆåŠŸèƒ½ - ä½¿ç”¨æŸ¥è¯¢å‚æ•°è€Œä¸æ˜¯JSON body
            if test_config.endpoint == "/api/elevator/cancel":
                response = await client.post(url, params=params)
            else:
                response = await client.post(url, json=params)
        else:
            raise Exception(f"Unsupported HTTP method: {test_config.http_method.value}")
        
        # è®°å½•å“åº”æ•°æ®
        try:
            response_json = response.json()
            result["response_data"] = response_json
        except:
            result["response_data"] = {"raw_response": response.text}
        
        # éªŒè¯å“åº”çŠ¶æ€
        if response.status_code == test_config.expected_status:
            result["status"] = "PASS"
        else:
            result["status"] = "FAIL"
            result["error_message"] = f"Expected status {test_config.expected_status}, got {response.status_code}"
        
        # æ‰§è¡Œç‰¹å®šéªŒè¯é€»è¾‘
        validation_result = _validate_test_response(test_config, response, result["response_data"])
        if not validation_result["valid"]:
            result["status"] = "FAIL"
            if result["error_message"]:
                result["error_message"] += f" | {validation_result['message']}"
            else:
                result["error_message"] = validation_result["message"]
        
    except Exception as e:
        result["status"] = "ERROR"
        result["error_message"] = str(e)
        logger.error(f"âŒ Test {test_config.name} execution error: {e}")
    
    # è®¡ç®—æ‰§è¡Œæ—¶é—´
    result["duration_ms"] = (time.time() - start_time) * 1000
    
    return result


def _validate_test_response(test_config: TestCaseConfig, 
                          response: httpx.Response,
                          response_data: Dict[str, Any]) -> Dict[str, Any]:
    """
    éªŒè¯æµ‹è¯•å“åº”
    
    Args:
        test_config: æµ‹è¯•é…ç½®
        response: HTTPå“åº”
        response_data: å“åº”æ•°æ®
        
    Returns:
        dict: éªŒè¯ç»“æžœ
    """
    validation_method = test_config.validation_method
    
    # åŸºç¡€éªŒè¯æ–¹æ³•
    if validation_method == "check_session_creation":
        if response_data and response_data.get("success"):
            return {"valid": True, "message": "Session creation validated"}
        else:
            return {"valid": False, "message": "Session creation failed"}
    
    elif validation_method == "check_api_info":
        if response_data and "name" in response_data:
            return {"valid": True, "message": "API info validated"}
        else:
            return {"valid": False, "message": "API info missing"}
    
    elif validation_method == "check_call_response":
        if response_data and response_data.get("success"):
            return {"valid": True, "message": "Call response validated"}
        else:
            return {"valid": False, "message": "Call response invalid"}
    
    elif validation_method in ["check_same_floor_error", "check_invalid_floor_error", "check_excessive_delay_error"]:
        # é”™è¯¯å¤„ç†æµ‹è¯•åº”è¯¥è¿”å›žå¤±è´¥çŠ¶æ€
        if response.status_code >= 400:
            return {"valid": True, "message": "Error handling validated"}
        else:
            return {"valid": False, "message": "Expected error response not received"}
    
    # é»˜è®¤éªŒè¯ï¼šåªæ£€æŸ¥HTTPçŠ¶æ€ç 
    return {"valid": True, "message": "Basic validation passed"}


def _calculate_test_statistics(test_results: List[Dict[str, Any]]) -> Dict[str, Any]:
    """
    è®¡ç®—æµ‹è¯•ç»Ÿè®¡ä¿¡æ¯
    
    Args:
        test_results: æµ‹è¯•ç»“æžœåˆ—è¡¨
        
    Returns:
        dict: ç»Ÿè®¡ä¿¡æ¯
    """
    total_tests = len(test_results)
    if total_tests == 0:
        return {"total_tests": 0}
    
    # æŒ‰çŠ¶æ€ç»Ÿè®¡
    status_counts = {}
    category_stats = {}
    total_duration = 0
    
    for result in test_results:
        status = result.get("status", "UNKNOWN")
        category = result.get("category", "Unknown")
        duration = result.get("duration_ms", 0)
        
        # çŠ¶æ€ç»Ÿè®¡
        status_counts[status] = status_counts.get(status, 0) + 1
        
        # åˆ†ç±»ç»Ÿè®¡
        if category not in category_stats:
            category_stats[category] = {"total": 0, "passed": 0, "failed": 0}
        
        category_stats[category]["total"] += 1
        if status == "PASS":
            category_stats[category]["passed"] += 1
        elif status in ["FAIL", "ERROR"]:
            category_stats[category]["failed"] += 1
        
        total_duration += duration
    
    # è®¡ç®—æˆåŠŸçŽ‡
    passed_tests = status_counts.get("PASS", 0)
    success_rate = (passed_tests / total_tests * 100) if total_tests > 0 else 0
    
    return {
        "total_tests": total_tests,
        "passed_tests": passed_tests,
        "failed_tests": status_counts.get("FAIL", 0),
        "error_tests": status_counts.get("ERROR", 0),
        "skipped_tests": status_counts.get("SKIP", 0),
        "success_rate": round(success_rate, 2),
        "total_duration_ms": total_duration,
        "average_duration_ms": round(total_duration / total_tests, 2) if total_tests > 0 else 0,
        "category_breakdown": category_stats,
        "status_distribution": status_counts
    }
